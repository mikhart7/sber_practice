{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1351005,
          "sourceType": "datasetVersion",
          "datasetId": 786286
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21a5e447e7e644b4b9f4ffb51676fd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7da5b61b9c8a4be8b21e1b161fa8d3a3",
              "IPY_MODEL_6d257e488bc5405aa2a706b43627c38c",
              "IPY_MODEL_9c630d696e934a5ea5670d295466be75"
            ],
            "layout": "IPY_MODEL_8493a4a63b024efa96fbd24936003b94"
          }
        },
        "7da5b61b9c8a4be8b21e1b161fa8d3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a3336aedbe47559c48495b335fc91e",
            "placeholder": "​",
            "style": "IPY_MODEL_d3742ef8fcc049c59fc032bd3564be54",
            "value": "Epoch 0:  69%"
          }
        },
        "6d257e488bc5405aa2a706b43627c38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b854b23d2d0461caa066e49e8d0cbd5",
            "max": 231,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bbaf617db1d49d0a5c86685a747a04c",
            "value": 160
          }
        },
        "9c630d696e934a5ea5670d295466be75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9244d049148e4107a9936a5326065180",
            "placeholder": "​",
            "style": "IPY_MODEL_c63d13e2334e41cba09b201ac317b702",
            "value": " 160/231 [02:21&lt;01:02,  1.13it/s, v_num=2]"
          }
        },
        "8493a4a63b024efa96fbd24936003b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f7a3336aedbe47559c48495b335fc91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3742ef8fcc049c59fc032bd3564be54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b854b23d2d0461caa066e49e8d0cbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbaf617db1d49d0a5c86685a747a04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9244d049148e4107a9936a5326065180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63d13e2334e41cba09b201ac317b702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import Tensor, nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:11:14.831350Z",
          "iopub.execute_input": "2025-04-03T11:11:14.831964Z",
          "iopub.status.idle": "2025-04-03T11:11:14.837590Z",
          "shell.execute_reply.started": "2025-04-03T11:11:14.831932Z",
          "shell.execute_reply": "2025-04-03T11:11:14.836205Z"
        },
        "id": "Wvf17JWJllYH"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning==2.4.0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:11:17.478801Z",
          "iopub.execute_input": "2025-04-03T11:11:17.479210Z",
          "iopub.status.idle": "2025-04-03T11:11:24.745093Z",
          "shell.execute_reply.started": "2025-04-03T11:11:17.479179Z",
          "shell.execute_reply": "2025-04-03T11:11:24.743653Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZoPWmlOllYM",
        "outputId": "a7fe52c6-2b84-4f4a-8fe4-21269e949c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightning==2.4.0 in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (2025.3.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (0.14.3)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (1.7.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (4.13.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0) (2.5.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.4.0) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning==2.4.0) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0) (3.10)\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning as L"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:11:28.018881Z",
          "iopub.execute_input": "2025-04-03T11:11:28.019260Z",
          "iopub.status.idle": "2025-04-03T11:11:29.842459Z",
          "shell.execute_reply.started": "2025-04-03T11:11:28.019226Z",
          "shell.execute_reply": "2025-04-03T11:11:29.841218Z"
        },
        "id": "Z6ajkq5EllYO"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dY-uPQsxoYV",
        "outputId": "1fb020d3-6360-40ab-8d97-9e57cae9cc80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a4c4403ebf0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"sample_data/reuters_headlines.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:11:30.001152Z",
          "iopub.execute_input": "2025-04-03T11:11:30.001794Z",
          "iopub.status.idle": "2025-04-03T11:11:30.382875Z",
          "shell.execute_reply.started": "2025-04-03T11:11:30.001760Z",
          "shell.execute_reply": "2025-04-03T11:11:30.381559Z"
        },
        "id": "dF-2Lf-1llYO"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, test_texts = train_test_split(list(data['Headlines']), test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:11:32.426227Z",
          "iopub.execute_input": "2025-04-03T11:11:32.426627Z",
          "iopub.status.idle": "2025-04-03T11:11:32.463031Z",
          "shell.execute_reply.started": "2025-04-03T11:11:32.426591Z",
          "shell.execute_reply": "2025-04-03T11:11:32.461945Z"
        },
        "id": "ghc92vCnllYP"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"yiyanghkust/finbert-tone\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:12:56.296217Z",
          "iopub.execute_input": "2025-04-03T11:12:56.296626Z",
          "iopub.status.idle": "2025-04-03T11:12:56.943495Z",
          "shell.execute_reply.started": "2025-04-03T11:12:56.296592Z",
          "shell.execute_reply": "2025-04-03T11:12:56.942262Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FZaE4OilllYP",
        "outputId": "fe7c0473-ca08-4e4e-e1d2-42a6717d7e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "class FinancialNewsDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        return text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:12:08.279056Z",
          "iopub.execute_input": "2025-04-03T11:12:08.279401Z",
          "iopub.status.idle": "2025-04-03T11:12:08.285290Z",
          "shell.execute_reply.started": "2025-04-03T11:12:08.279374Z",
          "shell.execute_reply": "2025-04-03T11:12:08.283896Z"
        },
        "id": "aQnpXLOEllYQ"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = FinancialNewsDataset(train_texts)\n",
        "test_data = FinancialNewsDataset(test_texts)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:12:11.752237Z",
          "iopub.execute_input": "2025-04-03T11:12:11.752616Z",
          "iopub.status.idle": "2025-04-03T11:12:11.757545Z",
          "shell.execute_reply.started": "2025-04-03T11:12:11.752582Z",
          "shell.execute_reply": "2025-04-03T11:12:11.756122Z"
        },
        "id": "DXoz2qwullYQ"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRYblXSxxpE7",
        "outputId": "fd173f35-86d7-4e8d-ee87-8eaa3daf278a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29493"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(\n",
        "    tokenizer: AutoTokenizer, batch: list[tuple[str, str]]\n",
        ") -> tuple[Tensor, Tensor]:\n",
        "    encoded_batch = tokenizer.batch_encode_plus(\n",
        "        batch, padding=\"longest\", return_tensors=\"pt\", return_token_type_ids=False)\n",
        "    return encoded_batch.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:20:34.359958Z",
          "iopub.execute_input": "2025-04-03T11:20:34.360317Z",
          "iopub.status.idle": "2025-04-03T11:20:34.366035Z",
          "shell.execute_reply.started": "2025-04-03T11:20:34.360289Z",
          "shell.execute_reply": "2025-04-03T11:20:34.364575Z"
        },
        "id": "zHqzHGZPllYR"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:28:19.335702Z",
          "iopub.execute_input": "2025-04-03T11:28:19.336244Z",
          "iopub.status.idle": "2025-04-03T11:28:19.349804Z",
          "shell.execute_reply.started": "2025-04-03T11:28:19.336203Z",
          "shell.execute_reply": "2025-04-03T11:28:19.348361Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMd3RTPjllYR",
        "outputId": "8d740069-6e09-4148-837e-3f3aff1cd8c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30873"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, collate_fn=lambda batch:collate_fn(tokenizer,batch))\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=True, collate_fn=lambda batch:collate_fn(tokenizer,batch))\n",
        "batch = next(iter(train_loader))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:20:36.324220Z",
          "iopub.execute_input": "2025-04-03T11:20:36.324584Z",
          "iopub.status.idle": "2025-04-03T11:20:36.335952Z",
          "shell.execute_reply.started": "2025-04-03T11:20:36.324552Z",
          "shell.execute_reply": "2025-04-03T11:20:36.334782Z"
        },
        "id": "k5OC8sasllYS"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)\n",
        "        self.A_v = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_scores = self.attn(x).squeeze(-1)  # (B, T)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=1)  # (B, T)\n",
        "        return torch.sum(attn_weights.unsqueeze(-1) * self.A_v(x), dim=1)  # (B, H)\n",
        "\n",
        "\n",
        "at = AttentionPooling(768, 1024).to(device)"
      ],
      "metadata": {
        "id": "oI3p0kESb2zt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= bert_model(batch['input_ids'], attention_mask=batch['attention_mask']).last_hidden_state"
      ],
      "metadata": {
        "id": "40YXovjpL05s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "at(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLyuCYcGMWDV",
        "outputId": "8b0b75eb-92e8-4b2d-8923-586b2a96550d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class EncoderDecoderModel(nn.Module):\n",
        "    def __init__(self, bert_model, hidden_dim=768, num_layers=2, nhead=4, max_length=100, vocab_size=len(tokenizer),dropout=1e-4, sent_dim=2048):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model  # ЭНКОДЕР (BERT)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.max_length = max_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.sent_dim = sent_dim\n",
        "\n",
        "\n",
        "        self.attn_pool = AttentionPooling(hidden_dim, sent_dim)\n",
        "        # Линейное отображение из энкодера\n",
        "        #self.projection = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Декодер\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=sent_dim, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Выходной слой для предсказания токенов\n",
        "        self.fc_out = nn.Linear(sent_dim, vocab_size)\n",
        "\n",
        "        # Генерация синусоидальных позиционных эмбеддингов\n",
        "        self.register_buffer(\"positional_encoding\", self.sinusoidal_positional_encoding(max_length, sent_dim))\n",
        "\n",
        "    def sinusoidal_positional_encoding(self, seq_length, hidden_dim):\n",
        "        position = torch.arange(seq_length).unsqueeze(1).float()  # (T, 1)\n",
        "        div_term = torch.exp(torch.arange(0, hidden_dim, 2).float() * (-math.log(10000.0) / hidden_dim))\n",
        "\n",
        "        pe = torch.zeros(seq_length, hidden_dim)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        return pe.unsqueeze(0)  # (1, T, H)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        batch_size, seq_length = input_ids.shape  # (B, T)\n",
        "\n",
        "        # ПРОГОН ЧЕРЕЗ ЭНКОДЕР (BERT)\n",
        "        with torch.no_grad():\n",
        "            encoded = self.bert(input_ids, attention_mask=attention_mask).last_hidden_state  # (B, T, H)\n",
        "\n",
        "        # Усредняем эмбеддинги, чтобы получить глобальное представление\n",
        "        text_embedding = self.attn_pool(encoded, attention_mask)  # (B, S)\n",
        "\n",
        "        # Декодерные входы (позиционные эмбеддинги)\n",
        "        tgt = torch.zeros((batch_size, seq_length, self.sent_dim), device=input_ids.device)  # (B, T, S)\n",
        "\n",
        "        # Добавляем синусоидальные позиции\n",
        "        tgt = tgt + self.positional_encoding[:, :seq_length, :]  # (B, T, S)\n",
        "\n",
        "        # ПРОГОН ЧЕРЕЗ ДЕКОДЕР\n",
        "        memory = text_embedding.unsqueeze(1)  # (B, 1, S)\n",
        "        decoder_output = self.transformer_decoder(tgt, memory, tgt_key_padding_mask=(attention_mask==0))  # (B, T, S)\n",
        "\n",
        "\n",
        "\n",
        "        # ПРОГОН ЧЕРЕЗ ВЫХОДНОЙ ЛИНЕЙНЫЙ СЛОЙ\n",
        "        token_logits = self.fc_out(decoder_output)  # (B, T, V)\n",
        "\n",
        "        return token_logits  # (B, T, V)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:12:25.445869Z",
          "iopub.execute_input": "2025-04-03T11:12:25.446229Z",
          "iopub.status.idle": "2025-04-03T11:12:25.457425Z",
          "shell.execute_reply.started": "2025-04-03T11:12:25.446199Z",
          "shell.execute_reply": "2025-04-03T11:12:25.456213Z"
        },
        "id": "i8ptesq3llYT"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningAutoencoder(L.LightningModule):\n",
        "    def __init__(self, model, learning_rate=1e-4):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        return self.model(input_ids, attention_mask)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "\n",
        "        targets = input_ids[:, 1:].contiguous()  # Сдвигаем цель на 1 вправо\n",
        "        outputs = outputs[:, :-1, :]  # Убираем последний предсказанный токен\n",
        "\n",
        "        loss = self.criterion(outputs.reshape(-1, self.model.vocab_size), targets.reshape(-1))\n",
        "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "\n",
        "        targets = input_ids[:, 1:].contiguous()\n",
        "        outputs = outputs[:, :-1, :]\n",
        "\n",
        "        val_loss = self.criterion(outputs.reshape(-1, self.model.vocab_size), targets.reshape(-1))\n",
        "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return {\n",
        "            \"loss\": val_loss,\n",
        "            \"preds\": outputs,\n",
        "        }\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n",
        "        # давайте кроме оптимизатора создадим ещё расписание для шага оптимизации\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": torch.optim.lr_scheduler.MultiStepLR(\n",
        "                optimizer,\n",
        "                milestones=[5, 10, 15],\n",
        "                gamma=0.1,\n",
        "            ),\n",
        "        }\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:12:32.138182Z",
          "iopub.execute_input": "2025-04-03T11:12:32.138564Z",
          "iopub.status.idle": "2025-04-03T11:12:32.147675Z",
          "shell.execute_reply.started": "2025-04-03T11:12:32.138531Z",
          "shell.execute_reply": "2025-04-03T11:12:32.146210Z"
        },
        "id": "zS7xEG_pllYU"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf lightning_logs"
      ],
      "metadata": {
        "id": "fPxboJcykUMQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
        "encoder_decoder_model = EncoderDecoderModel(bert_model).to(device)\n",
        "model = LightningAutoencoder(encoder_decoder_model).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:17:02.716551Z",
          "iopub.execute_input": "2025-04-03T11:17:02.717030Z",
          "iopub.status.idle": "2025-04-03T11:17:03.875392Z",
          "shell.execute_reply.started": "2025-04-03T11:17:02.716993Z",
          "shell.execute_reply": "2025-04-03T11:17:03.873349Z"
        },
        "collapsed": true,
        "id": "pDxnQuPxllYV"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "model(batch['input_ids'], attention_mask=batch['attention_mask']).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgG3R2GtQW1f",
        "outputId": "d302d78e-4c5f-42bf-e5ac-01ef93e041d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 27, 30873])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "id": "rZaQngIgiMYM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filename=\"{epoch}-{val_loss:.2f}\",\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        save_top_k=2,\n",
        "        save_last=True,\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "E7Dd_7yhkAcJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=15,\n",
        "    accelerator=\"auto\",\n",
        "    logger=TensorBoardLogger(save_dir=\".\"),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "trainer.fit(model, train_loader)\n",
        "trainer.validate(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689,
          "referenced_widgets": [
            "21a5e447e7e644b4b9f4ffb51676fd74",
            "7da5b61b9c8a4be8b21e1b161fa8d3a3",
            "6d257e488bc5405aa2a706b43627c38c",
            "9c630d696e934a5ea5670d295466be75",
            "8493a4a63b024efa96fbd24936003b94",
            "f7a3336aedbe47559c48495b335fc91e",
            "d3742ef8fcc049c59fc032bd3564be54",
            "1b854b23d2d0461caa066e49e8d0cbd5",
            "1bbaf617db1d49d0a5c86685a747a04c",
            "9244d049148e4107a9936a5326065180",
            "c63d13e2334e41cba09b201ac317b702"
          ]
        },
        "id": "wEbEW_f1gIVI",
        "outputId": "74b5e0a8-c6a9-441b-b2bb-b9edc6184152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name      | Type                | Params | Mode \n",
            "----------------------------------------------------------\n",
            "0 | model     | EncoderDecoderModel | 258 M  | train\n",
            "1 | criterion | CrossEntropyLoss    | 0      | train\n",
            "----------------------------------------------------------\n",
            "258 M     Trainable params\n",
            "0         Non-trainable params\n",
            "258 M     Total params\n",
            "1,034.152 Total estimated model params size (MB)\n",
            "36        Modules in train mode\n",
            "228       Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name      | Type                | Params | Mode \n",
            "----------------------------------------------------------\n",
            "0 | model     | EncoderDecoderModel | 258 M  | train\n",
            "1 | criterion | CrossEntropyLoss    | 0      | train\n",
            "----------------------------------------------------------\n",
            "258 M     Trainable params\n",
            "0         Non-trainable params\n",
            "258 M     Total params\n",
            "1,034.152 Total estimated model params size (MB)\n",
            "36        Modules in train mode\n",
            "228       Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21a5e447e7e644b4b9f4ffb51676fd74"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_loader))\n",
        "tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "4op0522E27_q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s8VgNalj6hRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(batch['input_ids'],batch['attention_mask'])\n",
        "out_tokens = out.argmax(dim=-1)\n",
        "tokenizer.batch_decode(out_tokens, skip_special_tokens=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T11:25:55.725630Z",
          "iopub.execute_input": "2025-04-03T11:25:55.726024Z",
          "iopub.status.idle": "2025-04-03T11:25:55.738665Z",
          "shell.execute_reply.started": "2025-04-03T11:25:55.725993Z",
          "shell.execute_reply": "2025-04-03T11:25:55.737467Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "DbTJu9IHllYW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = L.Trainer(accelerator=\"auto\", logger=False)\n",
        "bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
        "encoder_decoder_model = EncoderDecoderModel(bert_model).to(device)\n",
        "model = LightningAutoencoder(encoder_decoder_model).to(device)\n",
        "\n",
        "last_checkpoint_path = Path(\"/content/lightning_logs/version_1/checkpoints/epoch=9-step=5010.ckpt\")\n",
        "trainer.validate(\n",
        "    model,\n",
        "    train_loader,\n",
        "    ckpt_path=last_checkpoint_path,\n",
        ")"
      ],
      "metadata": {
        "id": "fGocnIL326wk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}